{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413ca7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\VSCode\\Uni\\iot\\Assignment\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 627.4973 - mae: 15.9839 - val_loss: 66.7945 - val_mae: 6.6282\n",
      "Epoch 2/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 51.9141 - mae: 5.0509 - val_loss: 7.8574 - val_mae: 2.0539\n",
      "Epoch 3/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 33.0122 - mae: 4.0932 - val_loss: 4.3826 - val_mae: 1.4965\n",
      "Epoch 4/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 28.2181 - mae: 3.7764 - val_loss: 3.2848 - val_mae: 1.2634\n",
      "Epoch 5/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 24.7636 - mae: 3.5300 - val_loss: 4.6557 - val_mae: 1.6747\n",
      "Epoch 6/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 22.9620 - mae: 3.3734 - val_loss: 3.0975 - val_mae: 1.2525\n",
      "Epoch 7/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 21.8157 - mae: 3.2516 - val_loss: 3.7188 - val_mae: 1.4169\n",
      "Epoch 8/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 20.4552 - mae: 3.1481 - val_loss: 3.4518 - val_mae: 1.3358\n",
      "Epoch 9/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 19.5572 - mae: 3.0617 - val_loss: 5.4319 - val_mae: 1.7442\n",
      "Epoch 10/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 18.5956 - mae: 2.9592 - val_loss: 2.9095 - val_mae: 1.0659\n",
      "Epoch 11/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 17.4479 - mae: 2.8527 - val_loss: 3.8034 - val_mae: 1.4366\n",
      "Epoch 12/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 16.7407 - mae: 2.7799 - val_loss: 3.4155 - val_mae: 1.2856\n",
      "Epoch 13/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 15.9334 - mae: 2.6896 - val_loss: 3.4383 - val_mae: 1.2512\n",
      "Epoch 14/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 15.2903 - mae: 2.6082 - val_loss: 3.3372 - val_mae: 1.3303\n",
      "Epoch 15/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 14.3909 - mae: 2.5182 - val_loss: 2.8159 - val_mae: 1.0159\n",
      "Epoch 16/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13.4495 - mae: 2.4125 - val_loss: 2.8560 - val_mae: 1.0754\n",
      "Epoch 17/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12.8538 - mae: 2.3324 - val_loss: 2.6740 - val_mae: 0.9460\n",
      "Epoch 18/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12.1242 - mae: 2.2398 - val_loss: 2.6647 - val_mae: 0.9369\n",
      "Epoch 19/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11.3257 - mae: 2.1653 - val_loss: 2.9522 - val_mae: 1.0614\n",
      "Epoch 20/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11.0614 - mae: 2.1276 - val_loss: 2.8539 - val_mae: 1.0675\n",
      "Epoch 21/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10.6928 - mae: 2.0816 - val_loss: 3.2998 - val_mae: 1.2331\n",
      "Epoch 22/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10.4127 - mae: 2.0487 - val_loss: 3.3873 - val_mae: 1.2682\n",
      "Epoch 23/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10.2035 - mae: 2.0257 - val_loss: 3.9187 - val_mae: 1.4466\n",
      "Epoch 24/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.9371 - mae: 1.9939 - val_loss: 3.2961 - val_mae: 1.2388\n",
      "Epoch 25/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.5565 - mae: 1.9394 - val_loss: 3.5126 - val_mae: 1.3696\n",
      "Epoch 26/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.3486 - mae: 1.9138 - val_loss: 3.2646 - val_mae: 1.1882\n",
      "Epoch 27/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.2046 - mae: 1.8831 - val_loss: 3.4566 - val_mae: 1.3842\n",
      "Epoch 28/200\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8.8174 - mae: 1.8304 - val_loss: 3.6060 - val_mae: 1.4487\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4156 - mae: 1.7643  \n",
      "Test MSE: 9.416\n",
      "Test RMSE: 3.068\n",
      "Test MAE: 1.764\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Konrad\\AppData\\Local\\Temp\\tmp65n2sokf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Konrad\\AppData\\Local\\Temp\\tmp65n2sokf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Konrad\\AppData\\Local\\Temp\\tmp65n2sokf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 24), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1826053517392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1826053519312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1826053520080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1826053520848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1826053520464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1826053010256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ----------------------\n",
    "# 1. Load CSV\n",
    "# ----------------------\n",
    "data = pd.read_csv(\"greenhouse_data.csv\")\n",
    "\n",
    "# ----------------------\n",
    "# 2. Time features\n",
    "# ----------------------\n",
    "data['DateTime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n",
    "data['Hour'] = data['DateTime'].dt.hour\n",
    "data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "\n",
    "# ----------------------\n",
    "# 3. Feature Engineering\n",
    "# ----------------------\n",
    "data['Temp_Avg'] = data[['Temperature Front', 'Temperature Middle', 'Temperature Back']].mean(axis=1)\n",
    "data['Hum_Avg'] = data[['Humidity Front', 'Humidity Middle', 'Humidity Back']].mean(axis=1)\n",
    "\n",
    "# ----------------------\n",
    "# 4. Lag features\n",
    "# ----------------------\n",
    "lag_steps = 10\n",
    "for lag in range(1, lag_steps + 1):\n",
    "    data[f'Temp_lag{lag}'] = data['Temp_Avg'].shift(lag)\n",
    "    data[f'Hum_lag{lag}'] = data['Hum_Avg'].shift(lag)\n",
    "\n",
    "# Targets (next-step prediction)\n",
    "data['Target_Temp'] = data['Temp_Avg'].shift(-1)\n",
    "data['Target_Hum'] = data['Hum_Avg'].shift(-1)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# ----------------------\n",
    "# 5. Feature selection\n",
    "# ----------------------\n",
    "features = (\n",
    "    ['Temp_Avg', 'Hum_Avg'] +\n",
    "    [f'Temp_lag{i}' for i in range(1, lag_steps + 1)] +\n",
    "    [f'Hum_lag{i}' for i in range(1, lag_steps + 1)] +\n",
    "    ['Hour_sin', 'Hour_cos']\n",
    ")\n",
    "\n",
    "X = data[features].values\n",
    "y = data[['Target_Temp', 'Target_Hum']].values\n",
    "\n",
    "# ----------------------\n",
    "# 6. Chronological train/test split\n",
    "# ----------------------\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# ----------------------\n",
    "# 7. Scale inputs\n",
    "# ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# 8. Build refined neural network\n",
    "# ----------------------\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 9. Train with early stopping\n",
    "# ----------------------\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 10. Evaluation\n",
    "# ----------------------\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test MSE: {test_loss:.3f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss):.3f}\")\n",
    "print(f\"Test MAE: {test_mae:.3f}\")\n",
    "\n",
    "# ----------------------\n",
    "# 11. Convert to TensorFlow Lite\n",
    "# ----------------------\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"greenhouse_model_lag10.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# ----------------------\n",
    "# 12. Save scaler parameters\n",
    "# ----------------------\n",
    "scaler_params = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"mean\": scaler.mean_,\n",
    "    \"scale\": scaler.scale_\n",
    "})\n",
    "\n",
    "scaler_params.to_csv(\"scaler_params.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
